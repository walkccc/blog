<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>論文筆記 PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation &#183; Peng-Yu's Blog</title>
<meta name=title content="論文筆記 PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation &#183; Peng-Yu's Blog"><meta name=keywords content="CVPR,paper,"><link rel=canonical href=https://blog.pengyuc.com/posts/paper/paper-pointnet/><link type=text/css rel=stylesheet href=/css/main.bundle.min.36c3cd7950e4533fa7da3150d972e3edf34d07f83c0264ff04cad0969dfdb3b8a7065b0ed6c730c6d34a7bad516cfc6f6a5917ab1fdb10b25f481f8a17b54c16.css integrity="sha512-NsPNeVDkUz+n2jFQ2XLj7fNNB/g8AmT/BMrQlp39s7inBlsO1scwxtNKe61RbPxvalkXqx/bELJfSB+KF7VMFg=="><script type=text/javascript src=/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.3ad74b33440334ca29f8801ec6dac1f314951cf580e503d49631816b48d1f28d03543275f92b651565b48045b90731f47595b1396214b8b6aa11c6990f867f7e.js integrity="sha512-OtdLM0QDNMop+IAextrB8xSVHPWA5QPUljGBa0jR8o0DVDJ1+StlFWW0gEW5BzH0dZWxOWIUuLaqEcaZD4Z/fg==" data-copy=Copy data-copied=Copied></script><script src=/lib/zoom/zoom.min.f592a181a15d2a5b042daa7f746c3721acf9063f8b6acd175d989129865a37d400ae0e85b640f9ad42cd98d1f8ad30931718cf8811abdcc5fcb264400d1a2b0c.js integrity="sha512-9ZKhgaFdKlsELap/dGw3Iaz5Bj+Las0XXZiRKYZaN9QArg6FtkD5rULNmNH4rTCTFxjPiBGr3MX8smRADRorDA=="></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://blog.pengyuc.com/posts/paper/paper-pointnet/"><meta property="og:site_name" content="Peng-Yu's Blog"><meta property="og:title" content="論文筆記 PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-10-09T00:00:00+00:00"><meta property="article:modified_time" content="2018-10-09T00:00:00+00:00"><meta property="article:tag" content="CVPR"><meta property="article:tag" content="Paper"><meta name=twitter:card content="summary"><meta name=twitter:title content="論文筆記 PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"論文筆記 PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation","headline":"論文筆記 PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation","inLanguage":"en","url":"https:\/\/blog.pengyuc.com\/posts\/paper\/paper-pointnet\/","author":{"@type":"Person","name":"Peng-Yu Chen"},"copyrightYear":"2018","dateCreated":"2018-10-09T00:00:00\u002b00:00","datePublished":"2018-10-09T00:00:00\u002b00:00","dateModified":"2018-10-09T00:00:00\u002b00:00","keywords":["CVPR","paper"],"mainEntityOfPage":"true","wordCount":"959"}]</script><meta name=author content="Peng-Yu Chen"><link href=https://pengyuc.com rel=me><link href=https://github.com/walkccc rel=me><link href=https://linkedin.com/in/pengyuc rel=me><script src=/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><link type=text/css rel=stylesheet href=/lib/katex/katex.min.7e7e35e3ef02b7b437449a44ca3fac62ec1ed39cb8312b680a00fe8ac60badc95b063b694636b8440856f7f5e8c2cc9e6b0efb581179b2656c7e1e97558c7096.css integrity="sha512-fn414+8Ct7Q3RJpEyj+sYuwe05y4MStoCgD+isYLrclbBjtpRja4RAhW9/Xowsyeaw77WBF5smVsfh6XVYxwlg=="><script defer src=/lib/katex/katex.min.cadd45c1af1f44bdaf196dc9b104f1daeb29043f0dc59155ffe22847510a04390a0b7a859400d420a626204f7fc5ddb07c19311de1c66b25e19c2559d3e126a8.js integrity="sha512-yt1Fwa8fRL2vGW3JsQTx2uspBD8NxZFV/+IoR1EKBDkKC3qFlADUIKYmIE9/xd2wfBkxHeHGayXhnCVZ0+EmqA=="></script><script defer src=/lib/katex/auto-render.min.e9b2833d28623d18c071d78ef13e9c79d695122d296af3dbcee7bf1bf6518b0565bab59939267fbc8f5faf696193c20f5caef3e7501969cfb306f6738032730d.js integrity="sha512-6bKDPShiPRjAcdeO8T6cedaVEi0pavPbzue/G/ZRiwVlurWZOSZ/vI9fr2lhk8IPXK7z51AZac+zBvZzgDJzDQ==" onload=renderMathInElement(document.body)></script><meta name=theme-color></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-base font-medium text-gray-500 hover:text-gray-900">Peng-Yu&rsquo;s Blog</a></nav><nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12"><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=Posts>Posts</p></a><a href=https://pengyuc.com target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><div><div class="cursor-pointer flex items-center nested-menu"><a class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title>Links
</a><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></div><div class="absolute menuhide"><div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl"><div class="flex flex-col space-y-3"><a href=https://walkccc.me/LeetCode/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>LeetCode Solutions</p></a><a href=https://www.pokemontcgp.ai target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>PokémonTCGP.ai</p></a></div></div></div></div><a href=https://github.com/walkccc target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400 ltr:mr-1 rtl:ml-1"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=Posts>Posts</p></a></li><li class=mt-1><a href=https://pengyuc.com target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a href class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Links</p><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></a></li><li class=mt-1><a href=https://walkccc.me/LeetCode/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>LeetCode Solutions</p></a></li><li class=mt-1><a href=https://www.pokemontcgp.ai target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>PokémonTCGP.ai</p></a></li><li class=mb-2></li><li class=mt-1><a href=https://github.com/walkccc target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul><hr><ul class="flex mt-4 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li class=mb-1><a href=/tags/ class="flex items-center"><p class="text-sm font-sm text-gray-500 hover:text-gray-900" title=Tags>Tags</p></a></li><li class=mb-1><a href=/categories/ class="flex items-center"><p class="text-sm font-sm text-gray-500 hover:text-gray-900" title=Categories>Categories</p></a></li></ul></div></label></div></div><div class="main-menu flex pb-3 flex-col items-end justify-between md:justify-start space-x-3"><div class="hidden md:flex items-center space-x-5"><a href=/tags/ class="flex items-center"><p class="text-xs font-light text-gray-500 hover:text-gray-900" title=Tags>Tags</p></a><a href=/categories/ class="flex items-center"><p class="text-xs font-light text-gray-500 hover:text-gray-900" title=Categories>Categories</p></a></div></div><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class=hidden><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/>Peng-Yu's Blog</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/posts/>Posts</a><span class="px-1 text-primary-500">/</span></li><li class=hidden><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/posts/paper/paper-pointnet/>論文筆記 PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">論文筆記 PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2018-10-09T00:00:00+00:00>9 October 2018</time><span class="px-2 text-primary-500">&#183;</span><span>959 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">5 mins</span><span class="px-2 text-primary-500">&#183;</span>
<script type=text/javascript src=/js/zen-mode.min.eea5245cf9244ecbdf2c150d1c8833226c1541cadf6e98f63a7c9192b1a3676df2c3ec603b14f4cfaaa53971fd9d8955640c0f405bf3de2b43ee7a5fb29ae721.js integrity="sha512-7qUkXPkkTsvfLBUNHIgzImwVQcrfbpj2OnyRkrGjZ23yw+xgOxT0z6qlOXH9nYlVZAwPQFvz3itD7npfsprnIQ=="></script><span class=mb-[2px]><span id=zen-mode-button class="text-lg hover:text-primary-500" title="Enable zen mode" data-title-i18n-disable="Enable zen mode" data-title-i18n-enable="Disable zen mode"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 50 50" width="50" height="50"><path fill="currentcolor" d="M12.980469 4C9.1204688 4 5.9804688 7.14 5.9804688 11L6 26H9.9804688V11c0-1.65 1.3400002-3 3.0000002-3H40.019531c1.66.0 3 1.35 3 3V39c0 1.65-1.34 3-3 3H29c0 1.54-.579062 2.94-1.539062 4H40.019531c3.86.0 7-3.14 7-7V11c0-3.86-3.14-7-7-7H12.980469zM7 28c-2.206.0-4 1.794-4 4V42c0 2.206 1.794 4 4 4H23c2.206.0 4-1.794 4-4V32c0-2.206-1.794-4-4-4H7zm0 4H23L23.001953 42H7V32z"/></svg></span></span></span></span></div><div class="flex flex-row flex-wrap items-center"></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/categories/paper/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Paper
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/categories/chinese/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Chinese
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/cvpr/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">CVPR
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/paper/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Paper</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Peng-Yu Chen" src=/img/blowfish_logo_hu_e74a130226122ae3.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Peng-Yu Chen</div><div class="text-sm text-neutral-700 dark:text-neutral-400">A little bit about you</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=mailto:me@pengyuc.com target=_blank aria-label=Email rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://pengyuc.com target=_blank aria-label=Link rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 640 512"><path fill="currentcolor" d="M172.5 131.1c55.6-55.59 148-55.59 203.6.0 50 50 57.4 129.7 16.3 187.2L391.3 319.9C381 334.2 361 337.6 346.7 327.3c-14.4-10.3-17.8-30.3-7.5-44.6L340.3 281.1C363.2 249 359.6 205.1 331.7 177.2c-31.4-31.4-82.5-31.4-114 0L105.5 289.5c-31.51 30.6-31.51 82.5.0 114C133.3 431.4 177.3 435 209.3 412.1L210.9 410.1C225.3 400.7 245.3 404 255.5 418.4 265.8 432.8 262.5 452.8 248.1 463.1L246.5 464.2c-58.4 41.1-136.3 34.5-186.29-15.4-56.469-56.5-56.469-148.1.0-204.5L172.5 131.1zM467.5 380c-56.5 56.5-148 56.5-204.5.0-50-50-56.5-128.8-15.4-186.3L248.7 192.1C258.1 177.8 278.1 174.4 293.3 184.7 307.7 194.1 311.1 214.1 300.8 229.3L299.7 230.9C276.8 262.1 280.4 306.9 308.3 334.8c31.4 31.4 82.5 31.4 114 0L534.5 222.5c31.5-31.5 31.5-83.4.0-114C506.7 80.63 462.7 76.99 430.7 99.9L429.1 101C414.7 111.3 394.7 107.1 384.5 93.58 374.2 79.2 377.5 59.21 391.9 48.94L393.5 47.82C451 6.731 529.8 13.25 579.8 63.24c56.5 56.46 56.5 148.06.0 204.46L467.5 380z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/walkccc target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://linkedin.com/in/pengyuc target=_blank aria-label=Linkedin rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-10"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#point-cloud-features>Point Cloud Features</a></li><li><a href=#deep-learning-on-3d-data>Deep Learning on 3D Data</a></li><li><a href=#deep-learning-on-unordered-sets>Deep Learning on Unordered Sets</a></li></ul><ul><li><a href=#41-properties-of-point-sets-in-mathbb-rn>4.1. Properties of Point Sets in \(\mathbb R^n\)</a></li><li><a href=#42-pointnet-architecture>4.2. PointNet Architecture</a><ul><li><a href=#symmetry-function-for-unordered-input>Symmetry Function for Unordered Input</a></li><li><a href=#local-and-global-information-aggregation>Local and Global Information Aggregation</a></li><li><a href=#joint-alignment-network>Joint Alignment Network</a></li></ul></li><li><a href=#43-theoretical-analysis>4.3. Theoretical Analysis</a><ul><li><a href=#universal-approximation>Universal approximation</a></li><li><a href=#bottleneck-dimension-and-stability>Bottleneck dimension and stability</a></li></ul></li></ul><ul><li><a href=#51-applications>5.1. Applications</a><ul><li><a href=#3d-object-classification>3D Object Classification</a></li><li><a href=#3d-object-part-segmentation>3D Object Part Segmentation</a></li><li><a href=#semantic-segmentation-in-scenes>Semantic Segmentation in Scenes</a></li></ul></li><li><a href=#52-architecture-design-analysis>5.2. Architecture Design Analysis</a></li><li><a href=#53-visualizing-pointnet>5.3. Visualizing PointNet</a></li><li><a href=#54-time-and-space-complexity-analysis>5.4. Time and Space Complexity Analysis</a></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#point-cloud-features>Point Cloud Features</a></li><li><a href=#deep-learning-on-3d-data>Deep Learning on 3D Data</a></li><li><a href=#deep-learning-on-unordered-sets>Deep Learning on Unordered Sets</a></li></ul><ul><li><a href=#41-properties-of-point-sets-in-mathbb-rn>4.1. Properties of Point Sets in \(\mathbb R^n\)</a></li><li><a href=#42-pointnet-architecture>4.2. PointNet Architecture</a><ul><li><a href=#symmetry-function-for-unordered-input>Symmetry Function for Unordered Input</a></li><li><a href=#local-and-global-information-aggregation>Local and Global Information Aggregation</a></li><li><a href=#joint-alignment-network>Joint Alignment Network</a></li></ul></li><li><a href=#43-theoretical-analysis>4.3. Theoretical Analysis</a><ul><li><a href=#universal-approximation>Universal approximation</a></li><li><a href=#bottleneck-dimension-and-stability>Bottleneck dimension and stability</a></li></ul></li></ul><ul><li><a href=#51-applications>5.1. Applications</a><ul><li><a href=#3d-object-classification>3D Object Classification</a></li><li><a href=#3d-object-part-segmentation>3D Object Part Segmentation</a></li><li><a href=#semantic-segmentation-in-scenes>Semantic Segmentation in Scenes</a></li></ul></li><li><a href=#52-architecture-design-analysis>5.2. Architecture Design Analysis</a></li><li><a href=#53-visualizing-pointnet>5.3. Visualizing PointNet</a></li><li><a href=#54-time-and-space-complexity-analysis>5.4. Time and Space Complexity Analysis</a></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})(),function(){var t,e=$("#TableOfContents");if(e.length>0){t=$(window);function n(){var s,o=t.scrollTop(),i=$(".anchor"),n="";if(i.each(function(e,t){t=$(t),t.offset().top-$(window).height()/3<=o&&(n=decodeURIComponent(t.attr("id")))}),s=e.find("a.active"),s.length==1&&s.eq(0).attr("href")=="#"+n)return!0;s.each(function(e,t){$(t).removeClass("active").siblings("ul").hide()}),e.find('a[href="#'+n+'"]').addClass("active"),e.find('a[href="#'+n+'"]').parentsUntil("#TableOfContents").each(function(e,t){$(t).children("a").parents("ul").show()})}t.on("scroll",n),$(document).ready(function(){e.find("a").parent("li").find("ul").hide(),n()})}}()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><p><a href=http://openaccess.thecvf.com/content_cvpr_2017/papers/Qi_PointNet_Deep_Learning_CVPR_2017_paper.pdf target=_blank>Paper Link</a></p><h1 class="relative group">1. Introduction<div id=1-introduction class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#1-introduction aria-label=Anchor>#</a></span></h1><p>這篇是 Stanford 在 CVPR 2017 所發表的 PointNet，從名字中可以知道是有關處理 3D 資
料的論文。全文目標就是要對點雲（point cloud）做各種分類，最關鍵的方法為：</p><ul><li>single symmetric function</li><li>max pooling（解決無序性）</li></ul><table><thead><tr><th style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy src=https://i.imgur.com/JzCGYq8.png alt></figure></th></tr></thead><tbody><tr><td style=text-align:center>Figure 1. <strong>Applications of PointNet.</strong> We propose a novel deep net architecture that consumes raw point cloud (set of points) without voxelization or rendering. It is a unified architecture that learns both global and local point features, providing a simple, efficient and effective approach for a number of 3D recognition tasks.</td></tr></tbody></table><h1 class="relative group">2. Related Work<div id=2-related-work class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#2-related-work aria-label=Anchor>#</a></span></h1><h2 class="relative group">Point Cloud Features<div id=point-cloud-features class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#point-cloud-features aria-label=Anchor>#</a></span></h2><p>點雲有 local 和 global features，而找尋適恰的特徵組合方式是很重要的。</p><h2 class="relative group">Deep Learning on 3D Data<div id=deep-learning-on-3d-data class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#deep-learning-on-3d-data aria-label=Anchor>#</a></span></h2><p>3D data 的表示方示，及記憶體耗費 issue。</p><h2 class="relative group">Deep Learning on Unordered Sets<div id=deep-learning-on-unordered-sets class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#deep-learning-on-unordered-sets aria-label=Anchor>#</a></span></h2><p>點雲具有無序的特性，但順序往往是做卷積很關鍵的一環。</p><h1 class="relative group">3. Problem Statement<div id=3-problem-statement class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#3-problem-statement aria-label=Anchor>#</a></span></h1><p>以 Classification 來說：</p><ul><li>輸入：\(\{P_i \mid i = 1, \dots, n\}\)，其中 \(P_i\) 為每個點的座標
\((x, y, z)\)</li><li>輸出：分類每一個點 \(P_i\) 到 class \(k\)</li></ul><h1 class="relative group">4. Deep Learning on Point Sets<div id=4-deep-learning-on-point-sets class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#4-deep-learning-on-point-sets aria-label=Anchor>#</a></span></h1><h2 class="relative group">4.1. Properties of Point Sets in \(\mathbb R^n\)<div id=41-properties-of-point-sets-in-mathbb-rn class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#41-properties-of-point-sets-in-mathbb-rn aria-label=Anchor>#</a></span></h2><p>本文網路中輸入資料的是 3D 空間中的點雲（point cloud），在
<a href=./2018/09/27/Papers/pointwise-cnn/>Pointwise Convolutional Neural Networks</a> 中
，已經有對點雲做了基本介紹，這裡重新簡單提一次點雲的幾個重要特性：</p><ol><li><p><strong>無序性</strong>：可以理解點雲為一 \(n \times 3\) 的矩陣（\(n\)：點數）。因為相
同的點雲可以由兩個不同的矩陣所表示。要知道，雖然輸入進來的資料是無序性的，但
在表示一張立體圖時，每個點之間其實是有順序關係的，而且會選擇使用卷積，也是要
考量<strong>有序</strong>的特徵才有意義。</p></li><li><p><strong>點與點之間的關係</strong>：這些點在歐式空間中，彼此有固定的距離。這意味著點不是孤
立的，相鄰點形成一個有意義的子集。因此，模型需要能夠捕獲附近點的局部結構，以
及局部結構之間的組合相互關係。</p></li><li><p><strong>轉換不變性</strong>：同一旋轉和平移不應影響任何點的分類結果。</p></li></ol><h2 class="relative group">4.2. PointNet Architecture<div id=42-pointnet-architecture class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#42-pointnet-architecture aria-label=Anchor>#</a></span></h2><table><thead><tr><th style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy src=https://i.imgur.com/0PIQdEn.png alt></figure></th></tr></thead><tbody><tr><td style=text-align:center>Figure 2. <strong>PointNet Architecture.</strong> The classification network takes \(n\) points as input, applies input and feature transformations, and then aggregates point features by max pooling. The output is classification scores for \(k\) classes. The segmentation network is an extension to the classification net. It concatenates global and local features and outputs per point scores. &ldquo;mlp&rdquo; stands for multi-layer perceptron, numbers in bracket are layer sizes. Batchnorm is used for all layers with ReLU. Dropout layers are used for the last mlp in classification net.</td></tr></tbody></table><h3 class="relative group">Symmetry Function for Unordered Input<div id=symmetry-function-for-unordered-input class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#symmetry-function-for-unordered-input aria-label=Anchor>#</a></span></h3><p>為了要使 model 不會受到輸入資料無序性的影響，傳統上有三個方法：</p><ol><li>sorting</li><li>RNN，但會因 permutation 的緣故固而 train 很久</li><li><strong>symmetric function</strong>（本文主角）</li></ol><p>此篇 paper 有提到方法 1. 和方法 2. 的兩個主要缺點，以致於不大可行：</p><ol><li>sorting 的缺點：noise，若 noise 數量過多，則會降低 sorting 後，資料有序的意義
性！</li><li>RNN：在 <a href=https://arxiv.org/pdf/1511.06391.pdf target=_blank>OrderMatters</a> 中，作者提到順序
性還是有必要的，而且不能被完美的刪去。</li></ol><p>為了解決 4.1. 中所提到無序性的問題，作者便提出了使用 max pooling 的方法：</p><p>$$
f(\{x_1, \dots, x_n\}) \approx g(h(x_1), \dots, h(x_n)), \tag{1}
$$</p><p>其中，</p><ul><li>\(f\)：\(2^{\mathbb R^N} \to \mathbb R\)</li><li>\(h\)：\(\mathbb R^N \to \mathbb R^K\)</li><li>\(g\)：\(\underbrace{\mathbb R^K \times \cdots \times \mathbb R^K}_{n} \to
\mathbb R\)：對稱函數</li></ul><p>這裡簡單做個參數上的說明：</p><ul><li>\(N\)：每一個點的維度，在這裡是 \(3\)，即 \((x, y, z)\) 三維。</li><li>\(h\)：mlp (multi-layer perceptron) 要逼近的 function，即：特徵提取，將 \(N
(3)\) 維 mapping 到 \(K (1024)\) 維，這裡的 \(1024\) 是作者選取一個<strong>足夠
大</strong>的數字，來降低誤差。</li><li>\(g\)：代表的是對稱函數，在離散數學的<strong>關係</strong>（Relation）中，symmetric 是一
個雙向的表示，透過對 \(K (1024)\) 個 features 中，每 \(n\) 個點做 max
pool，全部做完後會得到維度為 \(K (1024)\) 的 global feature。作者在附錄中有
對此處：「為何 mlp 提取夠多 features 誤差就會低」做數學證明，網路上許多文章沒
有對此做詳細的解讀，本文會試著盡量解釋之。</li></ul><p>paper 提到透過實驗，可以藉由 mlp 去逼近 \(h\) 和透過 single variable function
及 max poolinig function 去逼近對稱函數 \(g\)，透過一連串的 \(h\)，我們可以
學習到一個不錯的 \(f\)，其中</p><p>$$f = [f_1, \dots, f_K].$$</p><h3 class="relative group">Local and Global Information Aggregation<div id=local-and-global-information-aggregation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#local-and-global-information-aggregation aria-label=Anchor>#</a></span></h3><p>由 Fig 2 可以看出，global feature 只能做 Classification。透過式 (1)，可以得到一
個向量 \([f_1, \dots, f_K]\)，透過 Fig 2（Segmentation Network），我們將
global 點雲特徵（\(1024\)）接在每一個點本來的 \(64\) 個特徵維度，就可以得到
per point 的新 feature，而這個新 feature 能夠同時表 local 和 global 的訊息，並且
能被應用在 Segmentation 上。</p><h3 class="relative group">Joint Alignment Network<div id=joint-alignment-network class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#joint-alignment-network aria-label=Anchor>#</a></span></h3><p>透過預測一個「轉置矩陣」（Fig 2 中 T-net，大小分別為 \(3 \times 3\) 和 \(64
\times 64\)），同時為了避免 loss 過大，有了以下的 regulation：</p><p>$$
L_{reg} = ||I - AA^T||_F^2, \tag{2}
$$</p><p>其中，</p><ul><li>\(A\)：由迷你網絡預測的 features alignment 矩陣</li></ul><p>最後對整個網路做個簡單的說明：</p><ul><li><p>mlp：共享權重的卷積</p><ul><li>第一層的 kernel size 為 \(1 \times 3\)，因為每個點 \((x, y, z)\)</li><li>後面每一層的 kernel 大小都是 \(1 \times 1\)</li></ul><p>即：特徵提取層只是把每個點連接起來而已。經過兩組 T-net + mlp 後，對每一個點提
取 \(1024\) 維特徵，經過 max pool 後，變成 \(1 \times 1024\) 的全域特徵。
再經過一個 mlp 得到 \(k\) 個 score。</p></li></ul><h2 class="relative group">4.3. Theoretical Analysis<div id=43-theoretical-analysis class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#43-theoretical-analysis aria-label=Anchor>#</a></span></h2><h3 class="relative group">Universal approximation<div id=universal-approximation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#universal-approximation aria-label=Anchor>#</a></span></h3><p>此 paper 首先展示了神經網絡對連續 set functions 的逼近能力。通過 set functions
的連續性，輸入 point set 的小誤差不會嚴重的影響到函數值，例如 classification 或
segmentation 的分數。</p><blockquote><p><strong>Theorem 1.</strong> Suppose \(f: \mathcal X \to \mathbb R\) is a continuous set
function w.r.t Hausdorff distance \(d_H(\cdot, \cdot)\). \(\forall
\epsilon > 0\), \(\exists\) a continuous function \(h\) and a symmetric
function \(g(x_1, \dots, x_n) = \gamma \circ MAX\), such that for any \(S
\in \mathcal X\),</p><p>$$\Bigg |f(S) - \gamma \Big (MAX_{x_i \in S} \{h(x_i)\} \Big) \Bigg | &lt; \epsilon$$
where \(x_1, \dots, x_n\) is the full list of elements in \(S\) ordered
arbitrarily, \(\gamma\) is a continuous function, and \(MAX\) is a vector
max operator that takes \(n\) vectors as input and returns a new vector of
the element-wise maximum.</p></blockquote><p>此定理告訴我們，當在 max pooling 層時，給定夠多的神經元（即：本篇 paper 的 $K$
是夠大的），$f$ 能輕鬆的被逼近。</p><h3 class="relative group">Bottleneck dimension and stability<div id=bottleneck-dimension-and-stability class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#bottleneck-dimension-and-stability aria-label=Anchor>#</a></span></h3><p>理論上和實驗上，透過 max pooling，都會影響到網路的表達能力，但透過以下定理可以分
析出此網路的穩定性：</p><blockquote><p><strong>Theorem 2.</strong> Suppose \(\textbf u: \mathcal X \to \mathbb R^K\) such that
\(\textbf u = MAX_{x_i \in S} \{h(x_i)\}\) and \(f = \gamma \circ
\textbf u\). Then,</p><p>(a) \(\forall S\), \(\exists \mathcal C_S\), \(\mathcal N_S \subseteq
\mathcal X\), \(f(T) = f(S)\) if \(\mathcal C_S \subseteq T \subseteq
\mathcal N_S\)</p><p>(b) \(|\mathcal C_S| \le K\)</p></blockquote><h1 class="relative group">5. Experiment<div id=5-experiment class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#5-experiment aria-label=Anchor>#</a></span></h1><h2 class="relative group">5.1. Applications<div id=51-applications class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#51-applications aria-label=Anchor>#</a></span></h2><h3 class="relative group">3D Object Classification<div id=3d-object-classification class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#3d-object-classification aria-label=Anchor>#</a></span></h3><table><thead><tr><th style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy src=https://i.imgur.com/FDQPL1M.png alt></figure></th></tr></thead><tbody><tr><td style=text-align:center>Table 1. <strong>Classification results on ModelNet40.</strong> Our net achieves state-of-the-art among deep nets on 3D input.</td></tr></tbody></table><h3 class="relative group">3D Object Part Segmentation<div id=3d-object-part-segmentation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#3d-object-part-segmentation aria-label=Anchor>#</a></span></h3><table><thead><tr><th style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy src=https://i.imgur.com/wdl9ggG.png alt></figure></th></tr></thead><tbody><tr><td style=text-align:center>Table 2. <strong>Segmentation results on ShapeNet part dataset.</strong> Metric is mIoU(%) on points. We compare with two traditional methods and and a 3D fully convolutional network baseline proposed by us. Our PointNet method achieved the state-of-the-art in mIoU.</td></tr></tbody></table><table><thead><tr><th style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy src=https://i.imgur.com/PtrXCvA.png alt></figure></th></tr></thead><tbody><tr><td style=text-align:center>Figure 3. <strong>Qualitative results for part segmentation.</strong> We visualize the CAD part segmentation results across all 16 object categories. We show both results for partial simulated Kinect scans (left block) and complete ShapeNet CAD models (right block).</td></tr></tbody></table><h3 class="relative group">Semantic Segmentation in Scenes<div id=semantic-segmentation-in-scenes class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#semantic-segmentation-in-scenes aria-label=Anchor>#</a></span></h3><table><thead><tr><th style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy src=https://i.imgur.com/ZGytoQh.png alt></figure></th></tr></thead><tbody><tr><td style=text-align:center>Table 3. <strong>Results on semantic segmentation in scenes.</strong> Metric is average IoU over 13 classes (structural and furniture elements plus clutter) and classification accuracy calculated on points.</td></tr></tbody></table><table><thead><tr><th style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy src=https://i.imgur.com/UctOZFg.png alt></figure></th></tr></thead><tbody><tr><td style=text-align:center>Table 4. <strong>Results on 3D object detection in scenes.</strong> Metric is average precision with threshold IoU 0.5 computed in 3D volumes.</td></tr></tbody></table><table><thead><tr><th style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy src=https://i.imgur.com/hPOQIyi.png alt></figure></th></tr></thead><tbody><tr><td style=text-align:center>Figure 4. <strong>Qualitative results for semantic segmentation.</strong> Top row is input point cloud with color. Bottom row is output semantic segmentation result (on points) displayed in the same camera viewpoint as input.</td></tr></tbody></table><h2 class="relative group">5.2. Architecture Design Analysis<div id=52-architecture-design-analysis class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#52-architecture-design-analysis aria-label=Anchor>#</a></span></h2><h2 class="relative group">5.3. Visualizing PointNet<div id=53-visualizing-pointnet class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#53-visualizing-pointnet aria-label=Anchor>#</a></span></h2><h2 class="relative group">5.4. Time and Space Complexity Analysis<div id=54-time-and-space-complexity-analysis class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#54-time-and-space-complexity-analysis aria-label=Anchor>#</a></span></h2><table><thead><tr><th style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy src=https://i.imgur.com/Au60Gsn.png alt></figure></th></tr></thead><tbody><tr><td style=text-align:center>Table 6. <strong>Time and space complexity of deep architectures for 3D data classification.</strong> PointNet (vanilla) is the classification PointNet without input and feature transformations. FLOP stands for floating-point operation. The &ldquo;M&rdquo; stands for million. Subvolume and MVCNN used pooling on input data from multiple rotations or views, without which they have much inferior performance.</td></tr></tbody></table></div></div><script>var oid="views_posts/paper/paper-pointnet.md",oid_likes="likes_posts/paper/paper-pointnet.md"</script><script type=text/javascript src=/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/posts/paper/paper-octnet/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">論文筆記 OctNet: Learning Deep 3D Representations at High Resolutions</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2018-10-05T00:00:00+00:00>5 October 2018</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/posts/paper/paper-pointnet++/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">論文筆記 PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2018-10-14T00:00:00+00:00>14 October 2018</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Peng-Yu Chen</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://blog.pengyuc.com/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>